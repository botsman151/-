                                        Методы сбора и обработки данных из сети Интернет
Урок 1. Основы клиент-серверного взаимодействия. Работа с API.

Посмотреть документацию к API GitHub, разобраться как вывести список репозиториев для конкретного пользователя, сохранить JSON-вывод в файле *.json.
Изучить список открытых API (https://www.programmableweb.com/category/all/apis). Найти среди них любое, требующее авторизацию (любого типа). Выполнить запросы к нему, пройдя авторизацию. Ответ сервера записать в файл. Если нет желания заморачиваться с поиском, возьмите API вконтакте (https://vk.com/dev/first_guide). Сделайте запрос, чтобы получить список всех сообществ на которые вы подписаны.

lesson1.1.py

lesson1.1.json

lesson1.2.py

lesson1.2.json   

Урок 2. Парсинг данных. HTML, DOM, XPath.

Написать приложение и функцию, которые собирают основные новости с сайта на выбор dzen.ru, lenta.ru, mail.ru . Для парсинга использовать XPath Структура данных должна содержать: название источника, наименование новости, ссылку на новость, дата публикации.
Минимум один сайт максимум все.

lesson2.ipynb

Урок 3. Парсинг данных. HTML, Beautiful Soap.

Вариант 1 Необходимо собрать информацию о вакансиях на вводимую должность (используем input или через аргументы получаем должность) с сайтов HH(обязательно) и/или Superjob(по желанию). Приложение должно анализировать несколько страниц сайта (также вводим через input или аргументы). Получившийся список должен содержать в себе минимум: Наименование вакансии. Предлагаемую зарплату (разносим в три поля: минимальная и максимальная и валюта. цифры преобразуем к цифрам). Ссылку на саму вакансию. Сайт, откуда собрана вакансия. По желанию можно добавить ещё параметры вакансии (например, работодателя и расположение). Структура должна быть одинаковая для вакансий с обоих сайтов. Общий результат можно вывести с помощью dataFrame через pandas. Сохраните в json либо csv.

Вариант 2 Необходимо собрать информацию по продуктам питания с сайта: Список протестированных продуктов на сайте Роскачество Приложение должно анализировать несколько страниц сайта (вводим через input или аргументы). Получившийся список должен содержать: наименование продукта, все параметры (безопасность, натуральность, пищевая ценность, качество). Не забываем преобразовать к цифрам общую оценку. Сайт, откуда получена информация. Общий результат можно вывести с помощью dataFrame через Pandas. Сохраните в json либо csv.

lesson3.ipynb

hh_data.json

Урок 4. Система управления базами данных MongoDB в Python.

Развернуть у себя на компьютере/виртуальной машине/хостинге MongoDB и реализовать функцию, которая будет добавлять только новые вакансии/продукты в вашу базу.
Написать функцию, которая производит поиск и выводит на экран вакансии с заработной платой больше введённой суммы (необходимо анализировать оба поля зарплаты). Для тех, кто выполнил задание с Росконтролем - напишите запрос для поиска продуктов с рейтингом не ниже введенного или качеством не ниже введенного (то есть цифра вводится одна, а запрос проверяет оба поля).

lesson4.ipynb
